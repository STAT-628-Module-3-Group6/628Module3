{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. For each interested word/phrase, find the adjectives around this word. Should find the required word inside a sentence.\n",
    "2. Also generate a X matrix to represent whether the interested word/phrase appears. (1--appear, 0--no appear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from textblob import TextBlob\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 42 words\n",
    "\n",
    "words = [\"wait\", \"waiting\", \"waiter\", \"waitress\", \"serve\", \"service\", \"services\", \"staff\", \"paid\", \"price\",\"prices\",\n",
    "         \"place\", \"places\", \"order\", \"orders\", \"menu\", \"lunch\",  \"people\", \"table\", \"tables\", \"dinner\", \"times\", \"flavor\", \"minutes\", \"minute\",\n",
    "         \"area\", \"family\", \"location\", \"style\", \"buffet\", \"friends\", \"friend\", \"selection\", \"pay\", \"payment\",\n",
    "         \"amount\", \"variety\", \"pieces\", \"money\", \"bill\", \"server\", \"servers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#24 2-grams phrases\n",
    "phrases_2 = [('dim','sum'), ('fried','rice'), ('orange', 'chicken'), ('chow', 'mein'), ('pad', 'thai'), ('sour', 'soup'), ('hot', 'pot'), ('spring', 'rolls'), ('lo', 'mein'), ('bbq', 'pork'), ('mongolian', 'beef'), ('egg', 'roll'), ('wonton', 'soup'), ('soy', 'sauce'), ('ice', 'cream'), ('pork', 'belly'), ('milk', 'tea'), ('fried', 'chicken'),  ('sour', 'chicken'), ('white', 'rice'), ('sesame', 'chicken'), ('chicken', 'wings'), ('peking', 'duck'), ('bubble', 'tea')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 -grams phrases\n",
    "phrases_3 = [('egg', 'drop', 'soup'), ('beef', 'noodle', 'soup'), ('kung', 'pao', 'chicken'), ('chicken', 'fried', 'rice'), ('pork', 'fried', 'rice'), ('black', 'bean', 'sauce'), ('shrimp', 'fried', 'rice'), ('xiao', 'long', 'bao'), ('egg', 'foo', 'young'), ('dan', 'dan', 'noodles')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv(\"Chinese_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentencs_token_by_word = file[\"sentencs_token_by_word\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = file[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "sentencs_token_by_word = sentencs_token_by_word.tolist()\n",
    "sentencs_token_by_word = [ast.literal_eval(review) for review in sentencs_token_by_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_token = file[\"text_token\"].tolist()\n",
    "reviews_token = [ast.literal_eval(review) for review in reviews_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = file[\"bigram\"]\n",
    "bigram_token = bigram.tolist()\n",
    "bigram_token = [ast.literal_eval(review) for review in bigram_token]\n",
    "\n",
    "trigram = file[\"trigram\"]\n",
    "trigram_token = trigram.tolist()\n",
    "trigram_token = [ast.literal_eval(review) for review in trigram_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get The matrix for one-word, 1 means the word appears in the review\n",
    "data_phrases_1 = []\n",
    "\n",
    "for i in reviews_token:\n",
    "    score = []\n",
    "    for phrase in words:\n",
    "        if phrase in i:\n",
    "            score.append(1)\n",
    "        else:\n",
    "            score.append(0)\n",
    "    \n",
    "    data_phrases_1.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get The matrix for two-words and three_words, 1 means the word appears in the review\n",
    "data_phrases_2 = []\n",
    "\n",
    "for i in bigram_token:\n",
    "    score = []\n",
    "    for phrase in phrases_2:\n",
    "        if phrase in i:\n",
    "            score.append(1)\n",
    "        else:\n",
    "            score.append(0)\n",
    "    \n",
    "    data_phrases_2.append(score)\n",
    "    \n",
    "data_phrases_3 = []\n",
    "\n",
    "for i in trigram_token:\n",
    "    score = []\n",
    "    for phrase in phrases_3:\n",
    "        if phrase in i:\n",
    "            score.append(1)\n",
    "        else:\n",
    "            score.append(0)\n",
    "    \n",
    "    data_phrases_3.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array(data_phrases_1)\n",
    "X2 = np.array(data_phrases_2)\n",
    "X3 = np.array(data_phrases_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Code. Fine the adj for singleword/phrase(2 words)/phrase(3 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run 2-3 hours\n",
    "\n",
    "total_number = len(sentencs_token_by_word)\n",
    "\n",
    "## total_number = 40\n",
    "\n",
    "required_tag = np.array([\"JJ\", \"JJR\", \"JJS\",\"RB\"])  ## want to find adj for a given noun. Note: tag of \"not\" is RB\n",
    "\n",
    "total_adjective_1 = [None] * total_number  ## store the adj for seleted one-word in wach review\n",
    "total_adjective_2 = [None] * total_number  ## store the adj for seleted two-word in wach review\n",
    "total_adjective_3 = [None] * total_number  ## store the adj for seleted three-word in wach review\n",
    "# score_1 = [None] * total_number\n",
    "# score_2 = [None] * total_number\n",
    "# score_3 = [None] * total_number\n",
    "\n",
    "\n",
    "len1 = len(words)\n",
    "len2 = len(phrases_2)\n",
    "len3 = len(phrases_3)\n",
    "\n",
    "for indexReview in range(total_number):\n",
    "    \n",
    "    review = sentencs_token_by_word[indexReview]\n",
    "    NumberOfSentence = len(review)\n",
    "    \n",
    "    ## print(review)   \n",
    "    ## print(indexReview)\n",
    "    \n",
    "    if review == [None]:\n",
    "        total_adjective_1[indexReview] = list()\n",
    "        total_adjective_2[indexReview] = list()\n",
    "        total_adjective_3[indexReview] = list()\n",
    "        continue\n",
    "        \n",
    "    ## review_tag = [pos_tag(r) for r in review]  ## get the tag for each word\n",
    "    \n",
    "    review_tag = list()  ## Tag for a review\n",
    "    for r in review:  ## each sentence\n",
    "        tags = list()  ## tag for a sentence\n",
    "        for w in r:\n",
    "            word = list()\n",
    "            word.append(w)\n",
    "            tags.append(pos_tag(word)[0])\n",
    "        review_tag.append(tags)\n",
    "    \n",
    "    existWordsIndex1 = np.where(np.array(X1[indexReview,:]) == 1)[0] ## the existed target word in this review\n",
    "    existWordsIndex2 = np.where(np.array(X2[indexReview,:]) == 1)[0]\n",
    "    existWordsIndex3 = np.where(np.array(X3[indexReview,:]) == 1)[0]\n",
    "        \n",
    "        \n",
    "    ### part1: Deal with single-word\n",
    "    \n",
    "    if len(existWordsIndex1) > 0:\n",
    "        ## print(\"have words!!\")\n",
    "        adj = list()  ## a list of vector, each vector represent the adj for a selected single-word\n",
    "        score = list()  ## record the sentiment score for a sentence where the target word appears\n",
    "        ## iterate the words\n",
    "        for i in range(len1):\n",
    "            ## print(\"i: \",i)\n",
    "            adjForWord = []\n",
    "            ## scoreForWordsSentence = []\n",
    "            \n",
    "            if i in existWordsIndex1:\n",
    "                word = words[i]        \n",
    "                \n",
    "                ## print(\"target word: \", word)\n",
    "                \n",
    "                Score = 0\n",
    "                \n",
    "                for indexOfSentence in range(NumberOfSentence):\n",
    "                    sentence = review[indexOfSentence]\n",
    "                    tag = review_tag[indexOfSentence]\n",
    "\n",
    "                    if word in sentence:\n",
    "                        ##print(\"sentence: \", sentence)\n",
    "                        \n",
    "                        ## combine the token to a string, in order to calculate a sentiment score for this sentence\n",
    "                        sentenceString = \"\"\n",
    "                        for w in sentence:\n",
    "                            sentenceString += w\n",
    "                            sentenceString += \" \"\n",
    "                        \n",
    "                        Score += TextBlob(sentenceString).sentiment.polarity\n",
    "                        \n",
    "                        ## find adj/adv\n",
    "                        wordIndexArray = np.where(np.array(sentence) == word)[0]  ##  The index of word in one sentence, a word may exist more than one time                  \n",
    "                        for wordIndex in wordIndexArray:\n",
    "\n",
    "                            if wordIndex > 0:  ## The word does not appear in the beginning of a sentence, so may exist a adj before this word\n",
    "\n",
    "                                ## We assume that the adj appears either before the word or after the word                          \n",
    "                                if tag[wordIndex - 1][1] in required_tag:  ## exists adj before the word\n",
    "                                    if wordIndex - 2 >= 0:\n",
    "                                        if tag[wordIndex - 2][1] == \"not\":\n",
    "                                            nw = \"not \" + tag[wordIndex - 1][0]\n",
    "                                            adjForWord.append(nw)\n",
    "                                        else: \n",
    "                                            adjForWord.append(tag[wordIndex - 1][0])\n",
    "                                    else:\n",
    "                                        adjForWord.append(tag[wordIndex - 1][0])\n",
    "                                        \n",
    "                                    ## print(\"adj before the target word: \", adjForWord )\n",
    "                                else:\n",
    "                                    ### looking for required adj/verb after the word\n",
    "                                    j = wordIndex + 1\n",
    "                                    while j < len(sentence):\n",
    "                                        if tag[j][1] in required_tag:\n",
    "                                            adjForWord.append(tag[j][0])\n",
    "                                            j += 1\n",
    "                                        else:\n",
    "                                            break\n",
    "\n",
    "                            else:  ## The word is in the beginning of the sentence, find the adj after the word\n",
    "                                j = wordIndex + 1\n",
    "                                while j < len(sentence):\n",
    "                                    if tag[j][1] in required_tag:\n",
    "                                        adjForWord.append(tag[j][0])\n",
    "                                        j += 1\n",
    "                                    else:\n",
    "                                        break\n",
    "\n",
    "                            ## print(\"word in this sentence:\", adjForWord)\n",
    "                ## scoreForWordsSentence.append(Score)\n",
    "                Sscore = \"Score: \" + str(Score)\n",
    "                adjForWord.append(Sscore)\n",
    "                \n",
    "                ##print(\"wordForWholeReview: \", adjForWord)\n",
    "            adj.append(adjForWord)\n",
    "            ## score.append(scoreForWordsSentence)    \n",
    "            ## print(\"adj\", adj)\n",
    "                    \n",
    "    else:\n",
    "        \n",
    "        adj = list()\n",
    "        ## score = list()\n",
    "        ##print(\"adj\", adj)\n",
    "        \n",
    "    total_adjective_1[indexReview] = adj\n",
    "    ## score_1[indexReview] = score\n",
    "    \n",
    "    \n",
    "    ### part2: Deal with two-words phrase\n",
    "    \n",
    "    if len(existWordsIndex2) > 0:\n",
    "\n",
    "        adj = list()  ## a list of vector, each vector represent the adj for a selected single-word\n",
    "        ## score = list()\n",
    "        ## iterate the words\n",
    "        for i in range(len2):\n",
    "            ## print(\"i: \",i)\n",
    "            adjForWord = []\n",
    "            ## scoreForWordsSentence = []\n",
    "            if i in existWordsIndex2:\n",
    "                word = phrases_2[i]    ## the format is a tuple\n",
    "                firstWord = word[0]\n",
    "                secondWord = word[1]\n",
    "                \n",
    "                ##print(\"2-phrase: \", word)\n",
    "                Score = 0\n",
    "                \n",
    "                for indexOfSentence in range(NumberOfSentence):\n",
    "                    sentence = review[indexOfSentence]\n",
    "                    tag = review_tag[indexOfSentence]\n",
    "                    ## print(sentence)\n",
    "                    \n",
    "                    if firstWord in sentence:\n",
    "                        wordIndex1 = np.where(np.array(sentence) == firstWord)[0][0]  ##  The index of word in one sentence\n",
    "                        \n",
    "                        ## check whether the whole phrase is in the sentence:\n",
    "                        if wordIndex1 + 1 < len(sentence):\n",
    "                            if sentence[wordIndex1 + 1] != secondWord:\n",
    "                                continue\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                        ##print(\"sentence: \", sentence)\n",
    "                        \n",
    "                        ## combine the token to a string, in order to calculate a sentiment score for this sentence\n",
    "                        sentenceString = \"\"\n",
    "                        for w in sentence:\n",
    "                            sentenceString += w\n",
    "                            sentenceString += \" \"\n",
    "                        \n",
    "                        Score += TextBlob(sentenceString).sentiment.polarity\n",
    "                        \n",
    "                        if wordIndex1 > 0:  ## The word does not appear in the beginning of a sentence, so may exist a adj before this word\n",
    "                            \n",
    "                            ## We assume that the adj appears either before the word or after the word                          \n",
    "                            if tag[wordIndex1 - 1][1] in required_tag:  ## exists adj before the word\n",
    "                                \n",
    "                                if wordIndex1 - 2 >= 0:\n",
    "                                    if tag[wordIndex1 - 2][1] == \"not\":\n",
    "                                        nw = \"not \" + tag[wordIndex1 - 1][0]\n",
    "                                        adjForWord.append(nw)\n",
    "                                    else: \n",
    "                                        adjForWord.append(tag[wordIndex1 - 1][0])\n",
    "                                else:\n",
    "                                    adjForWord.append(tag[wordIndex1 - 1][0])\n",
    "                             \n",
    "                            else:\n",
    "                                ### looking for required adj/verb after the phrase\n",
    "                                j = wordIndex1 + 2\n",
    "                                while j < len(sentence):\n",
    "                                    if tag[j][1] in required_tag:\n",
    "                                        adjForWord.append(tag[j][0])\n",
    "                                        j += 1\n",
    "                                    else:\n",
    "                                        break\n",
    "                                        \n",
    "                        else:  ## The phrase is in the beginning of the sentence, find the adj after the word\n",
    "                            j = wordIndex1 + 2\n",
    "                            while j < len(sentence):\n",
    "                                if tag[j][1] in required_tag:\n",
    "                                    adjForWord.append(tag[j][0])\n",
    "                                    j += 1\n",
    "                                else:\n",
    "                                    break\n",
    "\n",
    "                            ##print(\"word in this sentence:\", adjForWord)\n",
    "                \n",
    "                Sscore = \"Score: \" + str(Score)\n",
    "                adjForWord.append(Sscore)\n",
    "                \n",
    "                ## scoreForWordsSentence.append(Score)\n",
    "                ##print(\"wordForWholeReview: \", adjForWord)\n",
    "            adj.append(adjForWord)\n",
    "            ## score.append(scoreForWordsSentence)    \n",
    "            ## print(\"adj\", adj)\n",
    "                    \n",
    "    else:\n",
    "        \n",
    "        adj = list()\n",
    "        ##score = list()\n",
    "        ##print(\"adj\", adj)\n",
    "        \n",
    "    total_adjective_2[indexReview] = adj\n",
    "    ##score_2[indexReview] = score    \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    ### part3: Deal with three-words phrase\n",
    "    \n",
    "    if len(existWordsIndex3) > 0:\n",
    "        \n",
    "        adj = list()  ## a list of vector, each vector represent the adj for a selected single-word\n",
    "        ## score = list()\n",
    "        ## iterate the words\n",
    "        for i in range(len3):\n",
    "            ## print(\"i: \",i)\n",
    "            adjForWord = []\n",
    "            ## scoreForWordsSentence = []\n",
    "            if i in existWordsIndex3:\n",
    "                word = phrases_3[i]    ## the format is a tuple\n",
    "                firstWord = word[0]\n",
    "                secondWord = word[1]\n",
    "                thirdWord = word[2]\n",
    "                \n",
    "                ##print(\"3-phrase: \", word)\n",
    "                Score = 0\n",
    "                \n",
    "                for indexOfSentence in range(NumberOfSentence):\n",
    "                    sentence = review[indexOfSentence]\n",
    "                    tag = review_tag[indexOfSentence]\n",
    "                    ## print(sentence)\n",
    "                    \n",
    "                    if firstWord in sentence:\n",
    "                        wordIndex1 = np.where(np.array(sentence) == firstWord)[0][0]  ##  The index of word in one sentence\n",
    "                        \n",
    "                        ## check whether the whole phrase is in the sentence:\n",
    "                        if wordIndex1 + 2 < len(sentence):\n",
    "                            if sentence[wordIndex1 + 1] != secondWord:\n",
    "                                continue\n",
    "                            else:\n",
    "                                if sentence[wordIndex1 + 2] != thirdWord:\n",
    "                                    continue\n",
    "                        else:\n",
    "                            continue\n",
    "                            \n",
    "                            \n",
    "                        ##print(\"sentence: \", sentence)\n",
    "                        \n",
    "                        ## combine the token to a string, in order to calculate a sentiment score for this sentence\n",
    "                        sentenceString = \"\"\n",
    "                        for w in sentence:\n",
    "                            sentenceString += w\n",
    "                            sentenceString += \" \"\n",
    "                        \n",
    "                        Score += TextBlob(sentenceString).sentiment.polarity\n",
    "                        \n",
    "\n",
    "                        if wordIndex1 > 0:  ## The word does not appear in the beginning of a sentence, so may exist a adj before this word\n",
    "                            \n",
    "                            ## We assume that the adj appears either before the word or after the word                          \n",
    "                            if tag[wordIndex1 - 1][1] in required_tag:  ## exists adj before the word\n",
    "                                \n",
    "                                if wordIndex1 - 2 >= 0:\n",
    "                                    if tag[wordIndex1 - 2][1] == \"not\":\n",
    "                                        nw = \"not \" + tag[wordIndex1 - 1][0]\n",
    "                                        adjForWord.append(nw)\n",
    "                                    else: \n",
    "                                        adjForWord.append(tag[wordIndex1 - 1][0])\n",
    "                                else:\n",
    "                                    adjForWord.append(tag[wordIndex1 - 1][0])\n",
    "                                    \n",
    "                                    \n",
    "                            else:\n",
    "                                ### looking for required adj/verb after the phrase\n",
    "                                j = wordIndex1 + 3\n",
    "                                while j < len(sentence):\n",
    "                                    if tag[j][1] in required_tag:\n",
    "                                        adjForWord.append(tag[j][0])\n",
    "                                        j += 1\n",
    "                                    else:\n",
    "                                        break\n",
    "                                        \n",
    "                        else:  ## The phrase is in the beginning of the sentence, find the adj after the word\n",
    "                            j = wordIndex1 + 3\n",
    "                            while j < len(sentence):\n",
    "                                if tag[j][1] in required_tag:\n",
    "                                    adjForWord.append(tag[j][0])\n",
    "                                    j += 1\n",
    "                                else:\n",
    "                                    break\n",
    "\n",
    "                            ##print(\"word in this sentence:\", adjForWord)\n",
    "                \n",
    "                Sscore = \"Score: \" + str(Score)\n",
    "                adjForWord.append(Sscore)\n",
    "                \n",
    "                ## scoreForWordsSentence.append(Score)\n",
    "                ##print(\"wordForWholeReview: \", adjForWord)\n",
    "            adj.append(adjForWord)\n",
    "            ## score.append(scoreForWordsSentence)\n",
    "            ## print(\"adj\", adj)\n",
    "                    \n",
    "    else:\n",
    "        \n",
    "        adj = list()\n",
    "        ## score = list()\n",
    "        ##print(\"adj\", adj)\n",
    "        \n",
    "    total_adjective_3[indexReview] = adj\n",
    "    ## score_3[indexReview] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe to store these adjs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_adjective_1_df = pd.DataFrame(total_adjective_1)\n",
    "total_adjective_1_df.columns = words\n",
    "total_adjective_1_df[\"business_index\"] = file[\"business_index\"]\n",
    "total_adjective_1_df[\"business_id\"] = file[\"business_id\"]\n",
    "total_adjective_1_df['stars'] = file['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_adjective_2_df = pd.DataFrame(total_adjective_2)\n",
    "total_adjective_2_df.columns = phrases_2\n",
    "total_adjective_2_df[\"business_index\"] = file[\"business_index\"]\n",
    "total_adjective_2_df[\"business_id\"] = file[\"business_id\"]\n",
    "total_adjective_2_df['stars'] = file['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_adjective_3_df = pd.DataFrame(total_adjective_3)\n",
    "total_adjective_3_df.columns = phrases_3\n",
    "total_adjective_3_df[\"business_index\"] = file[\"business_index\"]\n",
    "total_adjective_3_df[\"business_id\"] = file[\"business_id\"]\n",
    "total_adjective_3_df['stars'] = file['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_adjective_1_df.to_csv(\"total_adjective_1_df.csv\")\n",
    "total_adjective_2_df.to_csv(\"total_adjective_2_df.csv\")\n",
    "total_adjective_3_df.to_csv(\"total_adjective_3_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the file after close\n",
    "\n",
    "total_adjective_1_df = pd.read_csv(\"total_adjective_1_df.csv\")\n",
    "total_adjective_2_df = pd.read_csv(\"total_adjective_2_df.csv\")\n",
    "total_adjective_3_df = pd.read_csv(\"total_adjective_3_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_adjective_1_df  = total_adjective_1_df.iloc[:,1:]\n",
    "total_adjective_2_df  = total_adjective_2_df.iloc[:,1:]\n",
    "total_adjective_3_df  = total_adjective_3_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### the total number of adjs for each selected word/phrase\n",
    "\n",
    "count_1 = [0] * 42\n",
    "count_2 = [0] * 24\n",
    "count_3 = [0] * 10\n",
    "\n",
    "for i in range(total_number):\n",
    "    for j1 in range(42):\n",
    "        if total_adjective_1_df.iloc[i,j1] != None and type(total_adjective_1_df.iloc[i,j1]) == list:\n",
    "            length1 = len(total_adjective_1_df.iloc[i,j1])\n",
    "            if length1 > 0:\n",
    "                count_1[j1] += length1 - 1\n",
    "    for j2 in range(25):\n",
    "        if total_adjective_2_df.iloc[i,j2] != None and type(total_adjective_2_df.iloc[i,j2]) == list:\n",
    "            length2 = len(total_adjective_2_df.iloc[i,j2])\n",
    "            if length2 > 0:\n",
    "                count_2[j2] += length2 - 1\n",
    "    for j3 in range(10):\n",
    "        if total_adjective_3_df.iloc[i,j3] != None and type(total_adjective_3_df.iloc[i,j3]) == list:\n",
    "            length3 = len(total_adjective_3_df.iloc[i,j3])\n",
    "            if length3 > 0:\n",
    "                count_3[j3] += length3 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordAdjCount1_df = pd.DataFrame()\n",
    "wordAdjCount1_df[\"words\"] = words\n",
    "wordAdjCount1_df[\"adjCounts\"] = count_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordAdjCount1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordAdjCount2_df = pd.DataFrame()\n",
    "wordAdjCount2_df[\"words\"] = phrases_2\n",
    "wordAdjCount2_df[\"adjCounts\"] = count_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordAdjCount2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordAdjCount3_df = pd.DataFrame()\n",
    "wordAdjCount3_df[\"words\"] = phrases_3\n",
    "wordAdjCount3_df[\"adjCounts\"] = count_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordAdjCount3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split the adj for each business. Do not run it again. No use in final report\n",
    "\n",
    "total_number = file.shape[0]\n",
    "\n",
    "for i in range(total_number):  \n",
    "    indexRange = np.where(total_adjective_1_df[\"business_index\"] == i)[0]\n",
    "    temp1 = total_adjective_1_df.iloc[indexRange,0:-3]\n",
    "    temp2 = total_adjective_2_df.iloc[indexRange,0:-3]\n",
    "    temp3 = total_adjective_3_df.iloc[indexRange,0:-3]\n",
    "#     total_adjective = pd.concat( [temp1.reset_index(drop=True), \n",
    "#                                   temp2.reset_index(drop=True), temp3], axis=1)\n",
    "    \n",
    "    total_adjective = temp1\n",
    "    total_adjective[phrases_2] = temp2\n",
    "    total_adjective[phrases_3] = temp3\n",
    "    total_adjective[\"business_index\"] = file[\"business_index\"][indexRange]\n",
    "    total_adjective[\"business_id\"] = file[\"business_id\"][indexRange]\n",
    "    total_adjective['stars'] = file['stars'][indexRange]\n",
    "    name = \"eachBusiness/business_\" + str(i) + \".csv\"\n",
    "    total_adjective.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = range(134,139)\n",
    "X11 = X1[index,:]\n",
    "X12 = X2[index, :]\n",
    "X13 = X3[index, :]\n",
    "X1_ = np.hstack((X11,X12,X13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = np.array(file[\"stars\"])\n",
    "Y1_ = stars[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = words + phrases_2 + phrases_3  ## all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number = X1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine the adjs for single-noun word, stored in Words1\n",
    "\n",
    "Words1 = [None] * 42\n",
    "SumOfScore1 = [0] * 42\n",
    "\n",
    "for j in range(42):\n",
    "    adjs = list()\n",
    "    SCORE = 0\n",
    "    for i in range(total_number):\n",
    "        ## print(total_adjective_1_df.iloc[i,j])\n",
    "        if type(total_adjective_1_df.iloc[i,j]) != str:\n",
    "            continue\n",
    "            \n",
    "        item = ast.literal_eval(total_adjective_1_df.iloc[i,j])\n",
    "\n",
    "        if item != None and item != []:\n",
    "            if len(item) > 1:\n",
    "                word = item[0:-1]\n",
    "                \n",
    "                for w in word:\n",
    "                    adjs.append(w)\n",
    "                \n",
    "                score = item[-1]\n",
    "            else:\n",
    "                score = item[0]\n",
    "                \n",
    "            score = float(score[7:])\n",
    "            SCORE += score\n",
    "                \n",
    "    Words1[j] = adjs\n",
    "    SumOfScore1[j] = SCORE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['short',\n",
       "  'bad',\n",
       "  '20-30',\n",
       "  'not',\n",
       "  'least',\n",
       "  'not',\n",
       "  'really',\n",
       "  'quite',\n",
       "  'especially',\n",
       "  'long',\n",
       "  'long',\n",
       "  'prepared',\n",
       "  'never',\n",
       "  'long',\n",
       "  'not',\n",
       "  'even',\n",
       "  'not'],\n",
       " ['long', 'next'],\n",
       " ['first', 'not', 'often', 'actually'],\n",
       " ['sometimes'],\n",
       " ['not', 'green'],\n",
       " ['average',\n",
       "  'slightly',\n",
       "  'average',\n",
       "  'poor',\n",
       "  'average',\n",
       "  'huge',\n",
       "  'horrible',\n",
       "  'pretty',\n",
       "  'good',\n",
       "  'poor',\n",
       "  'terrible',\n",
       "  'good',\n",
       "  'not',\n",
       "  'great',\n",
       "  'non-dim',\n",
       "  'poor',\n",
       "  'poor',\n",
       "  'bad',\n",
       "  'honestly',\n",
       "  'horrible',\n",
       "  'good',\n",
       "  'busy',\n",
       "  'incredibly',\n",
       "  'clearly',\n",
       "  'not',\n",
       "  'interested',\n",
       "  'good',\n",
       "  'good',\n",
       "  'poor',\n",
       "  'worst',\n",
       "  'bad',\n",
       "  'bad',\n",
       "  'sometimes',\n",
       "  'bad',\n",
       "  'average',\n",
       "  'attentive',\n",
       "  'poor',\n",
       "  'back',\n",
       "  'generally',\n",
       "  'terrible',\n",
       "  'horrible',\n",
       "  'worst',\n",
       "  'also',\n",
       "  'exceptionally',\n",
       "  'bad',\n",
       "  'expensive',\n",
       "  'good',\n",
       "  'however',\n",
       "  'not',\n",
       "  'good',\n",
       "  'good',\n",
       "  'bad',\n",
       "  'also',\n",
       "  'snappy',\n",
       "  'terrible'],\n",
       " [],\n",
       " ['delicious', 'constantly', 'friendly', 'not'],\n",
       " ['slightly'],\n",
       " ['high', 'high', 'expensive', 'not'],\n",
       " ['reasonable',\n",
       "  'ridiculous',\n",
       "  'higher',\n",
       "  'reasonable',\n",
       "  'slightly',\n",
       "  'higher',\n",
       "  'reasonable',\n",
       "  'definitely',\n",
       "  'higher',\n",
       "  'fresh'],\n",
       " ['great',\n",
       "  'important',\n",
       "  'chinese',\n",
       "  'first',\n",
       "  'probably',\n",
       "  'pretty',\n",
       "  'good',\n",
       "  'also',\n",
       "  'mutli-ethnic',\n",
       "  'always',\n",
       "  'extremely',\n",
       "  'busy',\n",
       "  'usually',\n",
       "  'good',\n",
       "  'great',\n",
       "  'open',\n",
       "  'first',\n",
       "  'best',\n",
       "  'best',\n",
       "  'reasonably',\n",
       "  'close',\n",
       "  'nonetheless',\n",
       "  'constantly',\n",
       "  'good',\n",
       "  'pretty',\n",
       "  'good',\n",
       "  'good',\n",
       "  'great',\n",
       "  'good',\n",
       "  'ever',\n",
       "  'wrong',\n",
       "  'terrible',\n",
       "  'huge',\n",
       "  'chinese',\n",
       "  'great',\n",
       "  'low',\n",
       "  'great',\n",
       "  'back'],\n",
       " ['elsewhere', 'not', 'higher', 'whole'],\n",
       " ['also',\n",
       "  'larger',\n",
       "  'complete',\n",
       "  'regularly',\n",
       "  'visible',\n",
       "  'even',\n",
       "  'never',\n",
       "  'not',\n",
       "  'special'],\n",
       " [],\n",
       " ['wide', 'also', 'traditional', 'chinese', 'regular'],\n",
       " ['back', 'chinese', 'disappointed', 'entire'],\n",
       " ['chinese',\n",
       "  'different',\n",
       "  'white',\n",
       "  'really',\n",
       "  'full',\n",
       "  'aside',\n",
       "  'not',\n",
       "  'overwhelmed',\n",
       "  'many',\n",
       "  'many'],\n",
       " ['full', 'hot', 'fresh', 'next', 'middle-aged', 'asian'],\n",
       " ['many'],\n",
       " ['not', 'nice', 'normal'],\n",
       " ['quite', 'many', 'many', 'even', 'not', 'not', 'busy', 'never'],\n",
       " [],\n",
       " ['20-30'],\n",
       " ['last'],\n",
       " ['different'],\n",
       " ['whole', 'always', 'outstanding', 'out-of-town'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['luckily', 'best', 'much'],\n",
       " ['asian'],\n",
       " ['poor', 'large'],\n",
       " ['literally'],\n",
       " [],\n",
       " [],\n",
       " ['wide', 'wide', 'larger', 'wide', 'nice', 'good'],\n",
       " [],\n",
       " [],\n",
       " ['usually'],\n",
       " ['not', 'even', 'even'],\n",
       " ['nice', 'always', 'else', 'not', 'even', 'not', '3-4']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine the adjs for two-noun word, stored in Words2\n",
    "\n",
    "Words2 = [None] * 24\n",
    "SumOfScore2 = [0] * 24\n",
    "\n",
    "for j in range(24):\n",
    "    adjs = list()\n",
    "    SCORE = 0\n",
    "    for i in range(total_number):\n",
    "        if type(total_adjective_2_df.iloc[i,j]) != str:\n",
    "            continue\n",
    "            \n",
    "        item = ast.literal_eval(total_adjective_2_df.iloc[i,j])\n",
    "\n",
    "        if item != None and item != []:\n",
    "            if len(item) > 1:\n",
    "                word = item[0:-1]\n",
    "                \n",
    "                for w in word:\n",
    "                    adjs.append(w)\n",
    "                \n",
    "                score = item[-1]\n",
    "            else:\n",
    "                score = item[0]\n",
    "                \n",
    "            score = float(score[7:])\n",
    "            SCORE += score\n",
    "                \n",
    "    Words2[j] = adjs\n",
    "    SumOfScore2[j] = SCORE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine the adjs for there-noun word, stored in Words1\n",
    "\n",
    "\n",
    "Words3 = [None] * 10\n",
    "SumOfScore3 = [0] * 10\n",
    "\n",
    "for j in range(10):\n",
    "    adjs = list()\n",
    "    SCORE = 0\n",
    "    for i in range(total_number):\n",
    "        ## print(total_adjective_1_df.iloc[i,j])\n",
    "        if type(total_adjective_3_df.iloc[i,j]) != str:\n",
    "            continue\n",
    "            \n",
    "        item = ast.literal_eval(total_adjective_3_df.iloc[i,j])\n",
    "\n",
    "        if item != None and item != []:\n",
    "            if len(item) > 1:\n",
    "                word = item[0:-1]\n",
    "                \n",
    "                for w in word:\n",
    "                    adjs.append(w)\n",
    "                \n",
    "                score = item[-1]\n",
    "            else:\n",
    "                score = item[0]\n",
    "                \n",
    "            score = float(score[7:])\n",
    "            SCORE += score\n",
    "                \n",
    "    Words3[j] = adjs\n",
    "    SumOfScore3[j] = SCORE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordsTotal = Words1 + Words2 + Words3\n",
    "SumOfScore = SumOfScore1 + SumOfScore2 + SumOfScore3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Total number of appearce for adjs.\n",
    "\n",
    "numberOfAppear = np.hstack((np.sum(X1, 0), np.sum(X2, 0), np.sum(X3, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "AverageSumOfScore = [0] * 76\n",
    "for i in range(76):\n",
    "    AverageSumOfScore[i] = SumOfScore[i] / numberOfAppear[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordsTotalt = pd.DataFrame(np.array(WordsTotal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordsTotalt[\"AverageSumOfScore\"] = np.array(AverageSumOfScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordsTotalt.to_csv(\"WordsTotalt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Most Common adjs for \"waiting\"\n",
    "\n",
    "## wait/waiting(0,1) \n",
    "WaitWord = WordsTotal[0] + WordsTotal[1]\n",
    "d_wait = Counter(WaitWord)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('not', 4366),\n",
       " ('long', 2087),\n",
       " ('still', 517),\n",
       " ('never', 415),\n",
       " ('prepared', 385),\n",
       " ('short', 206),\n",
       " ('little', 180),\n",
       " ('even', 174),\n",
       " ('good', 166),\n",
       " ('busy', 160),\n",
       " ('always', 141),\n",
       " ('bad', 120),\n",
       " ('least', 113),\n",
       " ('sometimes', 107),\n",
       " ('much', 106),\n",
       " ('usually', 104),\n",
       " ('forever', 104),\n",
       " ('also', 100),\n",
       " ('ready', 99),\n",
       " ('almost', 96)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_wait.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Most Common adjs for \"service\"\n",
    "\n",
    "WaiterWord = WordsTotal[2] + WordsTotal[3] + WordsTotal[7] + WordsTotal[4] + WordsTotal[5] + WordsTotal[6] + WordsTotal[40] + WordsTotal[41]\n",
    "d_waiter = Counter(WaiterWord) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('friendly', 13903),\n",
       " ('good', 11905),\n",
       " ('great', 11848),\n",
       " ('not', 7454),\n",
       " ('nice', 4585),\n",
       " ('attentive', 4151),\n",
       " ('always', 3281),\n",
       " ('bad', 2912),\n",
       " ('also', 2388),\n",
       " ('really', 2336),\n",
       " ('horrible', 1783),\n",
       " ('terrible', 1714),\n",
       " ('pretty', 1640),\n",
       " ('poor', 1375),\n",
       " ('even', 1210),\n",
       " ('best', 1117),\n",
       " ('well', 1044),\n",
       " ('however', 868),\n",
       " ('extremely', 858),\n",
       " ('chinese', 854)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_waiter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Most Common adjs for \"price\"\n",
    "\n",
    "PayWord = WordsTotal[8] + WordsTotal[9] + WordsTotal[10] + WordsTotal[33] + WordsTotal[38] + WordsTotal[39]\n",
    "d_Pay = Counter(PayWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reasonable', 5615),\n",
       " ('good', 4662),\n",
       " ('great', 3501),\n",
       " ('not', 2955),\n",
       " ('high', 1276),\n",
       " ('low', 943),\n",
       " ('affordable', 830),\n",
       " ('higher', 798),\n",
       " ('little', 766),\n",
       " ('also', 654),\n",
       " ('extra', 635),\n",
       " ('back', 625),\n",
       " ('average', 602),\n",
       " ('bad', 576),\n",
       " ('pretty', 570),\n",
       " ('much', 569),\n",
       " ('really', 520),\n",
       " ('especially', 467),\n",
       " ('expensive', 446),\n",
       " ('even', 445),\n",
       " ('small', 441),\n",
       " ('full', 421),\n",
       " ('total', 401),\n",
       " ('well', 383),\n",
       " ('lower', 316),\n",
       " ('still', 294),\n",
       " ('chinese', 278),\n",
       " ('definitely', 272),\n",
       " ('regular', 267),\n",
       " ('special', 256),\n",
       " ('large', 244),\n",
       " ('friendly', 243),\n",
       " ('however', 220),\n",
       " ('big', 216),\n",
       " ('quite', 213),\n",
       " ('huge', 209),\n",
       " ('nice', 205),\n",
       " ('already', 197),\n",
       " ('overall', 192),\n",
       " ('never', 191),\n",
       " ('best', 190),\n",
       " ('delicious', 185),\n",
       " ('double', 164),\n",
       " ('willing', 161),\n",
       " ('generous', 157),\n",
       " ('first', 156),\n",
       " ('rather', 151),\n",
       " ('enough', 148),\n",
       " ('similar', 146),\n",
       " ('different', 143),\n",
       " ('always', 141),\n",
       " ('ridiculous', 139),\n",
       " ('extremely', 138),\n",
       " ('comparable', 135),\n",
       " ('slightly', 134),\n",
       " ('elsewhere', 132),\n",
       " ('actually', 122),\n",
       " ('inexpensive', 119),\n",
       " ('competitive', 111),\n",
       " ('fresh', 106),\n",
       " ('else', 106),\n",
       " ('ready', 105),\n",
       " ('twice', 102),\n",
       " ('almost', 97),\n",
       " ('least', 96),\n",
       " ('outrageous', 96),\n",
       " ('probably', 96),\n",
       " ('usually', 95),\n",
       " ('fantastic', 94),\n",
       " ('happy', 94),\n",
       " ('wrong', 91),\n",
       " ('normal', 91),\n",
       " ('close', 85),\n",
       " ('final', 83),\n",
       " ('ever', 81),\n",
       " ('atmosphere', 80),\n",
       " ('unbeatable', 77),\n",
       " ('fairly', 77),\n",
       " ('additional', 72),\n",
       " ('typical', 72),\n",
       " ('prepared', 71),\n",
       " ('yet', 69),\n",
       " ('due', 69),\n",
       " ('entire', 67),\n",
       " ('reasonably', 66),\n",
       " ('surprised', 65),\n",
       " ('maybe', 64),\n",
       " ('disappointed', 64),\n",
       " ('hard', 58),\n",
       " ('smaller', 57),\n",
       " ('new', 57),\n",
       " ('away', 55),\n",
       " ('finally', 55),\n",
       " ('relatively', 55),\n",
       " ('whole', 54),\n",
       " ('far', 51),\n",
       " ('many', 51),\n",
       " ('basically', 50),\n",
       " ('acceptable', 50),\n",
       " ('hot', 50),\n",
       " ('usual', 48),\n",
       " ('instead', 48),\n",
       " ('long', 45),\n",
       " ('next', 44),\n",
       " ('asian', 43),\n",
       " ('somewhere', 42),\n",
       " ('authentic', 42),\n",
       " ('anyway', 42),\n",
       " ('ridiculously', 41),\n",
       " ('able', 40),\n",
       " ('quickly', 40),\n",
       " ('exactly', 40),\n",
       " ('modest', 40),\n",
       " ('outstanding', 38),\n",
       " ('impressed', 36),\n",
       " ('anywhere', 36),\n",
       " ('free', 36),\n",
       " ('horrible', 36),\n",
       " ('honestly', 35),\n",
       " ('justified', 34),\n",
       " ('last', 34),\n",
       " ('incredible', 34),\n",
       " ('normally', 34),\n",
       " ('gladly', 33),\n",
       " ('actual', 33),\n",
       " ('terrible', 33),\n",
       " ('attentive', 33),\n",
       " ('bigger', 32),\n",
       " ('busy', 32),\n",
       " ('certainly', 32),\n",
       " ('original', 31),\n",
       " ('larger', 31),\n",
       " ('totally', 30),\n",
       " ('solid', 30),\n",
       " ('poor', 30),\n",
       " ('surprisingly', 29),\n",
       " ('satisfied', 29),\n",
       " ('tiny', 29),\n",
       " ('later', 28),\n",
       " ('somewhat', 27),\n",
       " ('generally', 27),\n",
       " ('general', 27),\n",
       " ('nearly', 26),\n",
       " ('recently', 26),\n",
       " ('separately', 26),\n",
       " ('soon', 25),\n",
       " ('certain', 25),\n",
       " ('second', 25),\n",
       " ('separate', 24),\n",
       " ('absolutely', 24),\n",
       " ('upscale', 24),\n",
       " ('simply', 24),\n",
       " ('late', 24),\n",
       " ('seriously', 24),\n",
       " ('unfortunately', 24),\n",
       " ('anymore', 23),\n",
       " ('true', 23),\n",
       " ('incredibly', 23),\n",
       " ('unbelievable', 23),\n",
       " ('regardless', 22),\n",
       " ('immediately', 22),\n",
       " ('literally', 22),\n",
       " ('aside', 21),\n",
       " ('automatically', 21),\n",
       " ('significantly', 21),\n",
       " ('obviously', 21),\n",
       " ('sometimes', 21),\n",
       " ('lowest', 21),\n",
       " ('roughly', 21),\n",
       " ('open', 21),\n",
       " ('real', 21),\n",
       " ('clearly', 20),\n",
       " ('easy', 20),\n",
       " ('main', 20),\n",
       " ('flat', 20),\n",
       " ('impressive', 19),\n",
       " ('worst', 19),\n",
       " ('resonable', 18),\n",
       " ('third', 18),\n",
       " ('exceptional', 18),\n",
       " ('unreasonable', 18),\n",
       " ('completely', 18),\n",
       " ('live', 17),\n",
       " ('old', 17),\n",
       " ('short', 17),\n",
       " ('happily', 17),\n",
       " ('astronomical', 17),\n",
       " ('alone', 17),\n",
       " ('upped', 16),\n",
       " ('lastly', 16),\n",
       " ('local', 16),\n",
       " ('extensive', 15),\n",
       " ('economical', 15),\n",
       " ('early', 15),\n",
       " ('easily', 15),\n",
       " ('negative', 15),\n",
       " ('single', 14),\n",
       " ('worse', 14),\n",
       " ('advertised', 14),\n",
       " ('ahead', 14),\n",
       " ('highest', 14),\n",
       " ('often', 14),\n",
       " ('bubble', 13),\n",
       " ('decently', 13),\n",
       " ('together', 13),\n",
       " ('barely', 13),\n",
       " ('otherwise', 13),\n",
       " ('highly', 13),\n",
       " ('healthy', 13),\n",
       " ('insanely', 13),\n",
       " ('carefully', 13),\n",
       " ('forever', 13),\n",
       " ('recent', 13),\n",
       " ('casual', 13),\n",
       " ('fabulous', 13),\n",
       " ('current', 12),\n",
       " ('individual', 12),\n",
       " ('likely', 12),\n",
       " ('pleased', 12),\n",
       " ('unbelievably', 12),\n",
       " ('crappy', 12),\n",
       " ('particularly', 12),\n",
       " ('basic', 12),\n",
       " ('available', 11),\n",
       " ('apparently', 11),\n",
       " ('courteous', 11),\n",
       " ('mostly', 11),\n",
       " ('green', 11),\n",
       " ('nearby', 10),\n",
       " ('worried', 10),\n",
       " ('therefore', 10),\n",
       " ('responsible', 10),\n",
       " ('attractive', 10),\n",
       " ('perfectly', 10),\n",
       " ('mainly', 10),\n",
       " ('senior', 10),\n",
       " ('everywhere', 10),\n",
       " ('overly', 10),\n",
       " ('limited', 9),\n",
       " ('10-', 9),\n",
       " ('greatest', 9),\n",
       " ('possible', 9),\n",
       " ('red', 9),\n",
       " ('several', 9),\n",
       " ('aware', 9),\n",
       " ('steadily', 9),\n",
       " ('daily', 9),\n",
       " ('ago', 9),\n",
       " ('arrive', 9),\n",
       " ('2-3', 9),\n",
       " ('accepted', 9),\n",
       " ('equal', 8),\n",
       " ('respectable', 8),\n",
       " ('promotional', 8),\n",
       " ('american', 8),\n",
       " ('hardly', 8),\n",
       " ('indeed', 8),\n",
       " ('important', 8),\n",
       " ('considerably', 8),\n",
       " ('regularly', 8),\n",
       " ('truly', 8),\n",
       " ('nicely', 8),\n",
       " ('prior', 8),\n",
       " ('amazingly', 8),\n",
       " ('5-', 8),\n",
       " ('substantial', 8),\n",
       " ('6-', 8),\n",
       " ('difficult', 8),\n",
       " ('correctly', 8),\n",
       " ('personally', 8),\n",
       " ('traditional', 8),\n",
       " ('tough', 8),\n",
       " ('accordingly', 8),\n",
       " ('massive', 8),\n",
       " ('wide', 7),\n",
       " ('10-15', 7),\n",
       " ('possibly', 7),\n",
       " ('rudely', 7),\n",
       " ('english', 7),\n",
       " ('ultimately', 7),\n",
       " ('typically', 7),\n",
       " ('perhaps', 7),\n",
       " ('importantly', 7),\n",
       " ('quiet', 7),\n",
       " ('heavy', 7),\n",
       " ('greater', 7),\n",
       " ('nasty', 7),\n",
       " ('consistently', 7),\n",
       " ('white', 7),\n",
       " ('biggest', 7),\n",
       " ('promptly', 7),\n",
       " ('comparatively', 7),\n",
       " ('seasonal', 7),\n",
       " ('furthermore', 7),\n",
       " ('initial', 7),\n",
       " ('vegetarian', 6),\n",
       " ('extraordinary', 6),\n",
       " ('1-2', 6),\n",
       " ('approximately', 6),\n",
       " ('unhappy', 6),\n",
       " ('noticeably', 6),\n",
       " ('ordinary', 6),\n",
       " ('lovely', 6),\n",
       " ('reluctantly', 6),\n",
       " ('unlimited', 6),\n",
       " ('non-member', 6),\n",
       " ('popular', 6),\n",
       " ('unheard', 6),\n",
       " ('politely', 6),\n",
       " ('additionally', 6),\n",
       " ('positive', 6),\n",
       " ('golden', 6),\n",
       " ('moderately', 6),\n",
       " ('hard-earned', 6),\n",
       " ('sadly', 6),\n",
       " ('dearly', 6),\n",
       " ('edible', 6),\n",
       " ('specifically', 5),\n",
       " ('conveniently', 5),\n",
       " ('eventually', 5),\n",
       " ('unreasonably', 5),\n",
       " ('easier', 5),\n",
       " ('agreeable', 5),\n",
       " ('grand', 5),\n",
       " ('empty', 5),\n",
       " ('understandable', 5),\n",
       " ('individually', 5),\n",
       " ('oily', 5),\n",
       " ('clear', 5),\n",
       " ('specific', 5),\n",
       " ('enjoyable', 5),\n",
       " ('common', 5),\n",
       " ('interested', 5),\n",
       " ('impossible', 5),\n",
       " ('pleasantly', 5),\n",
       " ('impeccable', 5),\n",
       " ('forward', 5),\n",
       " ('rich', 5),\n",
       " ('willingly', 5),\n",
       " ('stupid', 5),\n",
       " ('upper', 5),\n",
       " ('merely', 5),\n",
       " ('20-30', 5),\n",
       " ('originally', 5),\n",
       " ('justifiable', 5),\n",
       " ('western', 5),\n",
       " ('hopefully', 5),\n",
       " ('uptown', 5),\n",
       " ('obvious', 5),\n",
       " ('entirely', 5),\n",
       " ('young', 5),\n",
       " ('frankly', 5),\n",
       " ('properly', 5),\n",
       " ('sit-down', 5),\n",
       " ('memorable', 5),\n",
       " ('necessary', 5),\n",
       " ('alcoholic', 5),\n",
       " ('compatible', 5),\n",
       " ('enormous', 5),\n",
       " ('lucky', 5),\n",
       " ('directly', 4),\n",
       " ('7-8', 4),\n",
       " ('8-', 4),\n",
       " ('rarely', 4),\n",
       " ('altogether', 4),\n",
       " ('definately', 4),\n",
       " ('ish', 4),\n",
       " ('atrocious', 4),\n",
       " ('sudden', 4),\n",
       " ('manageable', 4),\n",
       " ('vietnamese', 4),\n",
       " ('locally', 4),\n",
       " ('-reasonable', 4),\n",
       " ('4-star', 4),\n",
       " ('safe', 4),\n",
       " ('affortable', 4),\n",
       " ('closely', 4),\n",
       " ('necessarily', 4),\n",
       " ('various', 4),\n",
       " ('serious', 4),\n",
       " ('loose', 4),\n",
       " ('drastic', 4),\n",
       " ('mixed', 4),\n",
       " ('previously', 4),\n",
       " ('wisely', 4),\n",
       " ('experienced', 4),\n",
       " ('valuable', 4),\n",
       " ('identical', 4),\n",
       " ('slowly', 4),\n",
       " ('sizable', 4),\n",
       " ('specially', 4),\n",
       " ('50-', 4),\n",
       " ('suitable', 4),\n",
       " ('25-', 4),\n",
       " ('tally', 4),\n",
       " ('inclusive', 4),\n",
       " ('nonetheless', 4),\n",
       " ('unnecessary', 4),\n",
       " ('upgraded', 4),\n",
       " ('timely', 4),\n",
       " ('5-6', 4),\n",
       " ('firstly', 3),\n",
       " ('impressively', 3),\n",
       " ('constant', 3),\n",
       " ('inattentive', 3),\n",
       " ('8-10', 3),\n",
       " ('40-50', 3),\n",
       " ('magically', 3),\n",
       " ('outlandish', 3),\n",
       " ('comfortable', 3),\n",
       " ('deliciously', 3),\n",
       " ('silly', 3),\n",
       " ('secondly', 3),\n",
       " ('unjustified', 3),\n",
       " ('pathetic', 3),\n",
       " ('authentically', 3),\n",
       " ('thus', 3),\n",
       " ('unmatched', 3),\n",
       " ('3-4x', 3),\n",
       " ('significant', 3),\n",
       " ('overwhelmed', 3),\n",
       " ('french', 3),\n",
       " ('25-30', 3),\n",
       " ('unnecessarily', 3),\n",
       " ('generously', 3),\n",
       " ('outrageously', 3),\n",
       " ('scary', 3),\n",
       " ('scrumptious', 3),\n",
       " ('doable', 3),\n",
       " ('solely', 3),\n",
       " ('remarkably', 3),\n",
       " ('spacious', 3),\n",
       " ('conscious', 3),\n",
       " ('electric', 3),\n",
       " ('unsatisfied', 3),\n",
       " ('unexpected', 3),\n",
       " ('surely', 3),\n",
       " ('12-', 3),\n",
       " ('adorable', 3),\n",
       " ('defiantly', 3),\n",
       " ('competitively', 3),\n",
       " ('excessive', 3),\n",
       " ('sensitive', 3),\n",
       " ('jelly', 3),\n",
       " ('extraordinarily', 3),\n",
       " ('10-20', 3),\n",
       " ('8-11', 3),\n",
       " ('disgustingly', 3),\n",
       " ('accessible', 3),\n",
       " ('6-8', 3),\n",
       " ('taiwanese', 3),\n",
       " ('retail', 3),\n",
       " ('concerned', 3),\n",
       " ('sky-high', 3),\n",
       " ('thoroughly', 3),\n",
       " ('essentially', 3),\n",
       " ('costly', 3),\n",
       " ('initially', 3),\n",
       " ('valid', 3),\n",
       " ('sloppy', 3),\n",
       " ('15-20', 3),\n",
       " ('complete', 3),\n",
       " ('japanese', 3),\n",
       " ('notably', 3),\n",
       " ('black', 3),\n",
       " ('gigantic', 3),\n",
       " ('shortly', 3),\n",
       " ('superior', 3),\n",
       " ('irritated', 3),\n",
       " ('luckily', 3),\n",
       " ('horrendous', 3),\n",
       " ('over-the-top', 2),\n",
       " ('nowhere', 2),\n",
       " ('precious', 2),\n",
       " ('largely', 2),\n",
       " ('incomparable', 2),\n",
       " ('false', 2),\n",
       " ('passable', 2),\n",
       " ('30-', 2),\n",
       " ('social', 2),\n",
       " ('fortunately', 2),\n",
       " ('unfavorable', 2),\n",
       " ('5-7', 2),\n",
       " ('virtually', 2),\n",
       " ('sincerely', 2),\n",
       " ('gross', 2),\n",
       " ('wary', 2),\n",
       " ('reasonble', 2),\n",
       " ('oddly', 2),\n",
       " ('iced', 2),\n",
       " ('add-on', 2),\n",
       " ('non-existent', 2),\n",
       " ('unusually', 2),\n",
       " ('2-3x', 2),\n",
       " ('adequately', 2),\n",
       " ('verbally', 2),\n",
       " ('marginally', 2),\n",
       " ('particular', 2),\n",
       " ('pretentious', 2),\n",
       " ('questionable', 2),\n",
       " ('adventurous', 2),\n",
       " ('personable', 2),\n",
       " ('organic', 2),\n",
       " ('7-', 2),\n",
       " ('unwilling', 2),\n",
       " ('poorly', 2),\n",
       " ('begrudgingly', 2),\n",
       " ('appalled', 2),\n",
       " ('shanghainese', 2),\n",
       " ('ive', 2),\n",
       " ('15-', 2),\n",
       " ('late-night', 2),\n",
       " ('13-15', 2),\n",
       " ('reasonalble', 2),\n",
       " ('afforable', 2),\n",
       " ('uninspired', 2),\n",
       " ('rediculous', 2),\n",
       " ('non-chinese', 2),\n",
       " ('7-9', 2),\n",
       " ('laughably', 2),\n",
       " ('astronomically', 2),\n",
       " ('unclear', 2),\n",
       " ('semi-affordable', 2),\n",
       " ('rapid', 2),\n",
       " ('not-so-cheap', 2),\n",
       " ('understandably', 2),\n",
       " ('soft', 2),\n",
       " ('underwhelmed', 2),\n",
       " ('occasionally', 2),\n",
       " ('familiar', 2),\n",
       " ('apart', 2),\n",
       " ('drastically', 2),\n",
       " ('dirt-cheap', 2),\n",
       " ('negligible', 2),\n",
       " ('older', 2),\n",
       " ('re-adjusted', 2),\n",
       " ('substantially', 2),\n",
       " ('1.50-', 2),\n",
       " ('egregious', 2),\n",
       " ('30-40', 2),\n",
       " ('accurately', 2),\n",
       " ('technically', 2),\n",
       " ('dual', 2),\n",
       " ('over-rated', 2),\n",
       " ('remarkable', 2),\n",
       " ('greatly', 2),\n",
       " ('uneaten', 2),\n",
       " ('broad', 2),\n",
       " ('finest', 2),\n",
       " ('20-25', 2),\n",
       " ('interestingly', 2),\n",
       " ('frequently', 2),\n",
       " ('exceptionally', 2),\n",
       " ('tremendous', 2),\n",
       " ('sensible', 2),\n",
       " ('measly', 2),\n",
       " ('freshly', 2),\n",
       " ('family-style', 2),\n",
       " ('economic', 2),\n",
       " ('professional', 2),\n",
       " ('incorrectly', 2),\n",
       " ('tolerable', 2),\n",
       " ('inedible', 2),\n",
       " ('7-10', 2),\n",
       " ('venetian', 2),\n",
       " ('1-', 2),\n",
       " ('hastily', 2),\n",
       " ('naturally', 2),\n",
       " ('3-', 2),\n",
       " ('financial', 2),\n",
       " ('badly', 2),\n",
       " ('continued', 2),\n",
       " ('2.99-', 2),\n",
       " ('corporate', 2),\n",
       " ('mere', 2),\n",
       " ('double-checked', 2),\n",
       " ('partial', 2),\n",
       " ('do-able', 2),\n",
       " ('sometime', 2),\n",
       " ('ludicrous', 2),\n",
       " ('lately', 2),\n",
       " ('constantly', 2),\n",
       " ('evenly', 2),\n",
       " ('ugly', 2),\n",
       " ('weekly', 2),\n",
       " ('classic', 2),\n",
       " ('simultaneously', 2),\n",
       " ('mid-high', 2),\n",
       " ('thankfully', 2),\n",
       " ('creative', 2),\n",
       " ('over-priced', 2),\n",
       " ('all-you-can', 2),\n",
       " ('strictly', 2),\n",
       " ('laughable', 2),\n",
       " ('tremendously', 2),\n",
       " ('4-5', 2),\n",
       " ('supposedly', 2),\n",
       " ('criminal', 2),\n",
       " ('repeatedly', 2),\n",
       " ('full-sized', 2),\n",
       " ('horribly', 2),\n",
       " ('major', 2),\n",
       " ('angry', 2),\n",
       " ('4-6', 2),\n",
       " ('preferable', 2),\n",
       " ('expansive', 2),\n",
       " ('automatic', 2),\n",
       " ('8-9', 2),\n",
       " ('offensive', 1),\n",
       " ('65-', 1),\n",
       " ('clean.unfortunally', 1),\n",
       " ('depressed', 1),\n",
       " ('2.35-', 1),\n",
       " ('unsanitary', 1),\n",
       " ('8:30am-11:30am', 1),\n",
       " ('8.50-13.99.', 1),\n",
       " ('righteous', 1),\n",
       " ('wrongly', 1),\n",
       " ('6-10', 1),\n",
       " ('friendly.affordable', 1),\n",
       " ('25-40', 1),\n",
       " ('temporarily', 1),\n",
       " ('high-tailed', 1),\n",
       " ('alcohol-ish', 1),\n",
       " ('mysteriously', 1),\n",
       " ('indicative', 1),\n",
       " ('scramble', 1),\n",
       " ('fondue', 1),\n",
       " ('humongous', 1),\n",
       " ('seperately', 1),\n",
       " ('incomparably', 1),\n",
       " ('13-', 1),\n",
       " ('gorgeous', 1),\n",
       " ('non-vip', 1),\n",
       " ('residential', 1),\n",
       " ('illegible', 1),\n",
       " ('cautious', 1),\n",
       " ('11-2', 1),\n",
       " ('likewise', 1),\n",
       " ('8.50-10.00', 1),\n",
       " ('50-75', 1),\n",
       " ('4.50-', 1),\n",
       " ('humble', 1),\n",
       " ('realistic', 1),\n",
       " ('17-18', 1),\n",
       " ('woefully', 1),\n",
       " ('orfinslly', 1),\n",
       " ('unfinished', 1),\n",
       " ('crazily', 1),\n",
       " ('pri-fixed', 1),\n",
       " ('abruptly', 1),\n",
       " ('unpleasantly', 1),\n",
       " ('wildly', 1),\n",
       " ('5-6ish', 1),\n",
       " ('potential', 1),\n",
       " ('arbitrary', 1),\n",
       " ('astonish', 1),\n",
       " ('vocal', 1),\n",
       " ('decent/reasonable', 1),\n",
       " ('12-14', 1),\n",
       " ('..there', 1),\n",
       " ('stupidly', 1),\n",
       " ('complex', 1),\n",
       " ('over-inflated', 1),\n",
       " ('irresistible', 1),\n",
       " ('independent', 1),\n",
       " ('5.99-', 1),\n",
       " ('western-chinese', 1),\n",
       " ('on-site', 1),\n",
       " ('advanced', 1),\n",
       " ('unbelieveably', 1),\n",
       " ('gently', 1),\n",
       " ('srsly', 1),\n",
       " ('agian', 1),\n",
       " ('standoff-ish', 1),\n",
       " ('prominently', 1),\n",
       " ('suddenly', 1),\n",
       " ('13-17', 1),\n",
       " ('20-30pp', 1),\n",
       " ('knowledgeable', 1),\n",
       " ('unbelievabely', 1),\n",
       " ('undercharged', 1),\n",
       " ('would.definitely', 1),\n",
       " ('uni', 1),\n",
       " ('problematic', 1),\n",
       " ('tip-inclusive', 1),\n",
       " ('lowere', 1),\n",
       " ('sizeable', 1),\n",
       " ('lunch-based', 1),\n",
       " ('nicest', 1),\n",
       " ('10pm-12am', 1),\n",
       " ('aggressively', 1),\n",
       " ('exotic', 1),\n",
       " ('2-4x', 1),\n",
       " ('shockingly', 1),\n",
       " ('noteven', 1),\n",
       " ('70-100', 1),\n",
       " ('amostphere', 1),\n",
       " ('aggressive', 1),\n",
       " ('occassionally', 1),\n",
       " ('115-125', 1),\n",
       " ('fair.definitely', 1),\n",
       " ('purposely', 1),\n",
       " ('unbelievablely', 1),\n",
       " ('unspoiled', 1),\n",
       " ('6-9', 1),\n",
       " ('unpretentious', 1),\n",
       " ('realistically', 1),\n",
       " ('4-7', 1),\n",
       " ('pre-tipped', 1),\n",
       " ('interchangeable', 1),\n",
       " ('contentious', 1),\n",
       " ('unable', 1),\n",
       " ('super-cheap', 1),\n",
       " ('smoothly', 1),\n",
       " ('substantive', 1),\n",
       " ('3-7', 1),\n",
       " ('awesomely', 1),\n",
       " ('50-50', 1),\n",
       " ('color-coded', 1),\n",
       " ('dramatically', 1),\n",
       " ('23-4', 1),\n",
       " ('feasible', 1),\n",
       " (\"'old-style\", 1),\n",
       " ('consequently', 1),\n",
       " ('appreciative', 1),\n",
       " ('expecially', 1),\n",
       " ('20-60+', 1),\n",
       " ('densely', 1),\n",
       " ('underportioned', 1),\n",
       " ('non-holiday', 1),\n",
       " ('non-alcoholic', 1),\n",
       " ('5-course', 1),\n",
       " ('cleverly', 1),\n",
       " ('partly', 1),\n",
       " ('practically', 1),\n",
       " ('suprisingly', 1),\n",
       " ('8-10ish', 1),\n",
       " ('visibly', 1),\n",
       " ('premiere', 1),\n",
       " ('undefeated', 1),\n",
       " ('a-little', 1),\n",
       " ('recognizable', 1),\n",
       " ('personal', 1),\n",
       " ('curry..reasonable', 1),\n",
       " ('11-15', 1),\n",
       " ('comparably', 1),\n",
       " ('not-too-substantial', 1),\n",
       " ('severely', 1),\n",
       " ('2-4', 1),\n",
       " ('palatable', 1),\n",
       " ('fastest', 1),\n",
       " ('disrespectfully', 1),\n",
       " ('gradually', 1),\n",
       " ('automatictly', 1),\n",
       " ('fabulously', 1),\n",
       " ('appropriately', 1),\n",
       " ('currently', 1),\n",
       " ('12-17', 1),\n",
       " ('fully', 1),\n",
       " ('16-', 1),\n",
       " ('unaffordable', 1),\n",
       " ('3-4', 1),\n",
       " ('18-', 1),\n",
       " ('humungous', 1),\n",
       " ('absurdly', 1),\n",
       " ('okayish', 1),\n",
       " ('southern', 1),\n",
       " ('2-3pp', 1),\n",
       " ('3.5-4.5', 1),\n",
       " ('10.95-13.00', 1),\n",
       " ('throughly', 1),\n",
       " ('20-', 1),\n",
       " ('anxiously', 1),\n",
       " ('14-15', 1),\n",
       " ('low-ish', 1),\n",
       " ('nite', 1),\n",
       " ('numerous', 1),\n",
       " ('11-year-old', 1),\n",
       " ('3.50-4.00', 1),\n",
       " ('largest', 1),\n",
       " ('bitterly', 1),\n",
       " ('three-dollar', 1),\n",
       " ('1995-96.', 1),\n",
       " ('eatable', 1),\n",
       " ('weirdly', 1),\n",
       " ('3.00-5.00', 1),\n",
       " ('18-20', 1),\n",
       " ('impractical', 1),\n",
       " ('dismissable', 1),\n",
       " ('decently-sized', 1),\n",
       " ('non-polite', 1),\n",
       " ('6-7', 1),\n",
       " ('deeelicious', 1),\n",
       " ('3-4pm', 1),\n",
       " ('favorable', 1),\n",
       " ('ecenomical', 1),\n",
       " ('80-', 1),\n",
       " ('3pm-5pm', 1),\n",
       " ('unburnt', 1),\n",
       " ('2-3/per', 1),\n",
       " ('fourth', 1),\n",
       " ('completable', 1),\n",
       " ('2-6', 1),\n",
       " ('all-day', 1),\n",
       " ('oh-so-reasonable', 1),\n",
       " ('60-70', 1),\n",
       " ('friday-sunday', 1),\n",
       " ('afffordable', 1),\n",
       " ('not-too-horrible', 1),\n",
       " ('rightfully', 1),\n",
       " ('high-ish', 1),\n",
       " ('miserably', 1),\n",
       " ('..final', 1),\n",
       " ('upper-end', 1),\n",
       " ('unmemorable', 1),\n",
       " ('romantic', 1),\n",
       " ('inconceivably', 1),\n",
       " ('uptight', 1),\n",
       " ('edpecially', 1),\n",
       " ('unfriendly', 1),\n",
       " ('nominal', 1),\n",
       " ('fantastically', 1),\n",
       " ('30-45', 1),\n",
       " ('reliable', 1),\n",
       " ('niether', 1),\n",
       " ('longest', 1),\n",
       " ('in-edible', 1),\n",
       " ('ostentatious', 1),\n",
       " ('2ndly', 1),\n",
       " ('miraculous', 1),\n",
       " ('fantastic-especially', 1),\n",
       " ('high/low//reasonable', 1),\n",
       " ('modern', 1),\n",
       " ('non-discounted', 1),\n",
       " ('shareable', 1),\n",
       " ('sky-rocketed', 1),\n",
       " ('previous', 1),\n",
       " ('unaccetable', 1),\n",
       " ('suspicious', 1),\n",
       " ('unpacked', 1),\n",
       " ('dissatisfied', 1),\n",
       " ('30-40.', 1),\n",
       " ('.that', 1),\n",
       " ('4-8', 1),\n",
       " ('friendly/authentic', 1),\n",
       " ('strong', 1),\n",
       " ('sophisticated', 1),\n",
       " ('atmoshpere', 1),\n",
       " ('20-40', 1),\n",
       " ('25-70', 1),\n",
       " ('temporary', 1),\n",
       " ('definetly', 1),\n",
       " ('definietly', 1),\n",
       " ('10-15/full', 1),\n",
       " ('fractional', 1),\n",
       " ('formal', 1),\n",
       " ('1:30-3:30pm', 1),\n",
       " ('mysterious', 1),\n",
       " ('legal', 1),\n",
       " ('mexican', 1),\n",
       " ('mathematically', 1),\n",
       " ('super-lazy', 1),\n",
       " ('national', 1),\n",
       " ('expectantly', 1),\n",
       " ('undelivered', 1),\n",
       " ('..reasonable', 1),\n",
       " ('annual', 1),\n",
       " ('strip-worthy', 1),\n",
       " ('******ridiculous', 1),\n",
       " ('addorable', 1),\n",
       " ('5-10', 1),\n",
       " ('delighted', 1),\n",
       " ('1130-130', 1),\n",
       " ('2-3.', 1),\n",
       " ('them-especially', 1),\n",
       " ('everything..even', 1),\n",
       " ('single-digit', 1),\n",
       " ('3-person', 1),\n",
       " ('3-6', 1),\n",
       " ('budget-minded', 1),\n",
       " ('not-', 1),\n",
       " ('nevertheless', 1),\n",
       " ('electronic', 1),\n",
       " ('oppressive', 1),\n",
       " ('non-combos', 1),\n",
       " ('tuesday-lunch-special', 1),\n",
       " ('2.68-3.48/', 1),\n",
       " ('10-12', 1),\n",
       " ('20-ish', 1),\n",
       " ('okay-ish', 1),\n",
       " ('wonderfully', 1),\n",
       " ('3-star', 1),\n",
       " ('angered', 1),\n",
       " ('preemptively', 1),\n",
       " ('pre-added', 1),\n",
       " ('craptastic', 1),\n",
       " ('quibble', 1),\n",
       " ('white-washed', 1),\n",
       " ('reasonanble', 1),\n",
       " ('natural', 1),\n",
       " ('normal-ish', 1),\n",
       " ('grudgingly', 1),\n",
       " ('figuratively', 1),\n",
       " ('luxurious', 1),\n",
       " ('terribly', 1),\n",
       " ('card..automatically', 1),\n",
       " ('medical', 1),\n",
       " ('contemporary', 1),\n",
       " ('13-20', 1),\n",
       " ('reasobable', 1),\n",
       " ('sarcastically', 1),\n",
       " ('steamtable', 1),\n",
       " ('meanwhile', 1),\n",
       " ('non-summerlicious', 1),\n",
       " ('northwestern', 1),\n",
       " ('lavish', 1),\n",
       " ('weak', 1),\n",
       " ('40-', 1),\n",
       " ('well-prepared', 1),\n",
       " ('reasonnable', 1),\n",
       " ('uniquely', 1),\n",
       " ('sporadically', 1),\n",
       " ('generically', 1),\n",
       " ('8-something', 1),\n",
       " ('12-18', 1),\n",
       " ('not-too-bad', 1),\n",
       " ('4.95-', 1),\n",
       " ('2-', 1),\n",
       " ('expectable', 1),\n",
       " ('2.5-3.5', 1),\n",
       " ('instantly', 1),\n",
       " ('~6/dish', 1),\n",
       " ('overdue', 1),\n",
       " ('*reasonable', 1),\n",
       " ('addictive', 1),\n",
       " ('ginormous', 1),\n",
       " ('dependable', 1),\n",
       " ('pre-loaded', 1),\n",
       " ('big-dollar', 1),\n",
       " ('unacceptable', 1),\n",
       " ('inly', 1),\n",
       " ('proudly', 1),\n",
       " ('unforgivable', 1),\n",
       " ('effective', 1),\n",
       " ('ouch', 1),\n",
       " ('foolish', 1),\n",
       " ('multi-coloured', 1),\n",
       " ('cal', 1),\n",
       " ('nitpicky', 1),\n",
       " ('espcially', 1),\n",
       " ('2.28-', 1),\n",
       " ('lest', 1),\n",
       " ('super-slightly', 1),\n",
       " ('nose', 1),\n",
       " ('super-reasonable', 1),\n",
       " ('.punishable', 1),\n",
       " ('5-15', 1),\n",
       " ('up-front', 1),\n",
       " ('forgivable', 1),\n",
       " ('permanently', 1),\n",
       " ('11-30/person', 1),\n",
       " ('10-15.00', 1),\n",
       " ('conservative', 1),\n",
       " ('later-especially', 1),\n",
       " ('related', 1),\n",
       " ('moderate/reasonable', 1),\n",
       " ('genorous', 1),\n",
       " ('unpredictable', 1),\n",
       " ('risky', 1),\n",
       " ('curious', 1),\n",
       " ('truthfully', 1),\n",
       " ('300-900', 1),\n",
       " ('painfully', 1),\n",
       " ('inexcusable', 1),\n",
       " ('mathematical', 1),\n",
       " ('sympathetic', 1),\n",
       " ('unlocked', 1),\n",
       " ('8-10.', 1),\n",
       " ('non-asian', 1),\n",
       " ('modestly', 1),\n",
       " ('markedly', 1),\n",
       " ('2x-3x', 1),\n",
       " ('non-happy-hour', 1),\n",
       " ('43-ish', 1),\n",
       " ('budget-friendly', 1),\n",
       " ('12-15', 1),\n",
       " ('socal', 1),\n",
       " (\"'typical\", 1),\n",
       " ('nutty', 1),\n",
       " ('3-5', 1),\n",
       " ('raisonnable', 1),\n",
       " ('..really', 1),\n",
       " ('chinese-american', 1),\n",
       " ('weakest', 1),\n",
       " ('cash-only', 1),\n",
       " ('fine..especially', 1),\n",
       " ('imperial', 1),\n",
       " ('unintentionally', 1),\n",
       " ('littlest', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_Pay.most_common()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
