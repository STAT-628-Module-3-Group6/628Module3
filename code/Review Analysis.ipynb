{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction\n",
    "#Extract some 2/3-grams phrases \n",
    "#Foods and service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = pd.read_csv(\"./Chinese_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#25 2-grams phrases\n",
    "phrases_2 = [('dim','sum'), ('fried','rice'), ('orange', 'chicken'), ('chow', 'mein'), ('pad', 'thai'), ('sour', 'soup'), ('hot', 'pot'), ('spring', 'rolls'), ('lo', 'mein'), ('bbq', 'pork'), ('mongolian', 'beef'), ('egg', 'roll'), ('wonton', 'soup'), ('soy', 'sauce'), ('ice', 'cream'), ('pork', 'belly'), ('milk', 'tea'), ('fried', 'chicken'),  ('sour', 'chicken'), ('white', 'rice'), ('sesame', 'chicken'), ('chicken', 'wings'), ('peking', 'duck'), ('bubble', 'tea')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 -grams phrases\n",
    "phrases_3 = [('egg', 'drop', 'soup'), ('beef', 'noodle', 'soup'), ('kung', 'pao', 'chicken'), ('chicken', 'fried', 'rice'), ('pork', 'fried', 'rice'), ('black', 'bean', 'sauce'), ('shrimp', 'fried', 'rice'), ('xiao', 'long', 'bao'), ('egg', 'foo', 'young'), ('dan', 'dan', 'noodles')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#88183 has keyword \"service\"\n",
    "data_service = []\n",
    "for i in file[\"text_token\"]:\n",
    "    if \"service\" in i:\n",
    "        data_service.append(1)\n",
    "    else:\n",
    "        data_service.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the csv get the string, thus convert the string to list\n",
    "import ast\n",
    "bigram = file[\"bigram\"]\n",
    "bigram_token = bigram.tolist()\n",
    "bigram_token = [ast.literal_eval(review) for review in bigram_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram = file[\"trigram\"]\n",
    "trigram_token = trigram.tolist()\n",
    "trigram_token = [ast.literal_eval(review) for review in trigram_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data of phrases\n",
    "data_phrases_2 = []\n",
    "\n",
    "for i in bigram_token:\n",
    "    score = []\n",
    "    for phrase in phrases_2:\n",
    "        if phrase in i:\n",
    "            score.append(1)\n",
    "        else:\n",
    "            score.append(0)\n",
    "    \n",
    "    data_phrases_2.append(score)\n",
    "    \n",
    "data_phrases_3 = []\n",
    "\n",
    "for i in trigram_token:\n",
    "    score = []\n",
    "    for phrase in phrases_3:\n",
    "        if phrase in i:\n",
    "            score.append(1)\n",
    "        else:\n",
    "            score.append(0)\n",
    "    \n",
    "    data_phrases_3.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the data\n",
    "#100 thousands data are all zero\n",
    "data = []\n",
    "length = len(data_service)\n",
    "for i in range(0, length):\n",
    "    score = []\n",
    "    score = [data_service[i]] + data_phrases_2[i] + data_phrases_3[i]\n",
    "    data.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit in the linear regression\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data)\n",
    "Y = file[\"stars\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LinearRegression().fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.501942019360378"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03522927,  0.00625635,  0.02764026,  0.11075855, -0.10948779,\n",
       "        0.06560973,  0.09240044,  0.27035717,  0.03505628,  0.00941428,\n",
       "        0.08158958,  0.19745566, -0.21047643,  0.12009486, -0.49484404,\n",
       "        0.18601939,  0.42759434,  0.03865716,  0.01413144,  0.0979552 ,\n",
       "       -0.05235997, -0.32971932,  0.0271465 ,  0.13886758,  0.11011196,\n",
       "       -0.00214659,  0.00084683,  0.31571651,  0.01030967,  0.03672473,\n",
       "        0.11921404,  0.23020313,  0.02867714,  0.1658348 ,  0.16104009,\n",
       "        0.27892855])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['service', ('dim', 'sum'), ('fried', 'rice'), ('orange', 'chicken'), ('chow', 'mein'), ('pad', 'thai'), ('sour', 'soup'), ('hot', 'pot'), ('spring', 'rolls'), ('lo', 'mein'), ('bbq', 'pork'), ('mongolian', 'beef'), ('egg', 'roll'), ('wonton', 'soup'), ('soy', 'sauce'), ('ice', 'cream'), ('pork', 'belly'), ('milk', 'tea'), ('fried', 'chicken'), ('egg', 'drop'), ('sour', 'chicken'), ('white', 'rice'), ('sesame', 'chicken'), ('chicken', 'wings'), ('peking', 'duck'), ('bubble', 'tea'), ('egg', 'drop', 'soup'), ('beef', 'noodle', 'soup'), ('kung', 'pao', 'chicken'), ('chicken', 'fried', 'rice'), ('pork', 'fried', 'rice'), ('black', 'bean', 'sauce'), ('shrimp', 'fried', 'rice'), ('xiao', 'long', 'bao'), ('egg', 'foo', 'young'), ('dan', 'dan', 'noodles')]\n"
     ]
    }
   ],
   "source": [
    "name = [\"service\"] + phrases_2 + phrases_3\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['girlfriend', 'went', 'dinner', 'emerald', 'chinese', 'thursday', 'night', 'workout', 'arrived', 'around', '7:30pm', 'seated', 'short', 'wait', 'browsing', 'menu', 'brief', 'discussion', 'waiter', 'ordered', 'seafood', 'noodles', '3', 'item', 'mix', 'meat', 'plate', 'bbq', 'pork', 'chicken', 'duck', 'food', 'came', 'soon', 'thereafter', 'hot', 'delicious', 'large', 'portions', 'lots', 'seafood', 'seafood', 'noodles', 'mix', 'meat', 'plate', 'came', 'good', 'cuts', 'meat', 'correct', 'sauces', 'meal', 'received', 'fortune', 'cookies', 'dessert', 'food', 'food', 'good', 'quality', 'ingredients', 'tasted', 'fresh', 'dishes', 'tasted', 'well', 'made', 'food', 'average', 'nothing', 'stood', 'even', 'though', 'quite', 'hungry', 'price', 'price', 'high', 'comparative', 'chinese', 'cuisine', 'comparable', 'large', 'western', 'restaurant', 'chains', 'service', 'service', 'average', 'slightly', 'average', 'common', 'malaise', 'chinese', 'restaurants', 'poor', 'service', 'waiter/waitresses', 'overworked', 'impatient', 'unattentive', 'emerald', 'chinese', 'no', 'exception', 'waiting', 'staff', 'restaurant', 'appear', 'rushed', 'impatient', 'services', 'needs', 'met', 'staff', 'rushed', 'grumpy..', 'decor', 'emerald', 'tasteful', 'decorations', 'comfortable', 'chairs', 'nice', 'tablecloths', 'sufficient', 'room', 'navigate', 'tables', 'overall', 'good', 'meal', 'large', 'portions', 'received', 'average', 'service', 'paid', 'slightly', 'hoped', 'meal', '3.1', '5.0']\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[\"text_token\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
